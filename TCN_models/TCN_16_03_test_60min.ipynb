{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "\n",
    "import os, math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.82 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tcn import TCN\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import Input, Model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def model(test_data, train_data):\n",
    "    test_time = test_data['time']\n",
    "    test_gl_value = test_data['gl_value']\n",
    "    \n",
    "    test_data.drop(columns = ['time'], inplace = True)\n",
    "    train_data.rename(columns = {'bolus_type_normal dual':'bolus_type_normal_dual', 'bolus_type_square dual':'bolus_type_square_dual'}, inplace = True)\n",
    "    train_data.drop(columns = ['time'], inplace = True)\n",
    "    \n",
    "    empty_train_col = [0]*len(train_data)\n",
    "    for i, item in enumerate(test_data.columns):\n",
    "        if item not in train_data.columns:\n",
    "            train_data.insert(i, item, empty_train_col)\n",
    "\n",
    "    empty_test_col = [0]*len(test_data)\n",
    "    for i, item in enumerate(train_data.columns):\n",
    "        if item not in test_data.columns:\n",
    "            test_data.insert(i, item, empty_test_col)\n",
    "    \n",
    "    X_data = train_data.drop(columns = ['gl_predict'])\n",
    "    y_data = train_data[['gl_predict']]\n",
    "    input_dim = X_data.shape[1]\n",
    "    \n",
    "    scaler_x = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "    scaler_x.fit(X_data)\n",
    "    scaler_y.fit(y_data)\n",
    "    scaled_X_train_data = scaler_x.transform(X_data)\n",
    "    scaled_y_train_data = scaler_y.transform(y_data)\n",
    "    scaled_X_train_data = np.reshape(scaled_X_train_data, (scaled_X_train_data.shape[0], 1, scaled_X_train_data.shape[1]))\n",
    "    \n",
    "    batch_size, timesteps, input_dim = 1, 1, input_dim\n",
    "    i = Input(batch_shape=(batch_size, timesteps, input_dim))\n",
    "    o = TCN(return_sequences = False)(i)\n",
    "    o = Dense(1)(o)\n",
    "\n",
    "    model = Model(inputs=[i], outputs=[o])\n",
    "    model.compile(optimizer = 'adam', loss = 'mse')\n",
    "\n",
    "    x, y = scaled_X_train_data, scaled_y_train_data\n",
    "    model.fit(x, y, epochs = 20)\n",
    "    X_test_data = test_data.drop(columns = ['gl_predict'])\n",
    "    y_test_data = test_data[['gl_predict']]\n",
    "    scaled_X_test_data = scaler_x.transform(X_test_data)\n",
    "    scaled_X_test_data = np.reshape(scaled_X_test_data, (scaled_X_test_data.shape[0], 1, scaled_X_test_data.shape[1]))\n",
    "    prediction = model.predict(scaled_X_test_data, batch_size = 1)\n",
    "    scaled_prediction = scaler_y.inverse_transform(prediction)\n",
    "    \n",
    "    final_output = pd.DataFrame(columns = ['timestamp', 'predicted_BGL_value'])\n",
    "    final_output['timestamp'] = test_time\n",
    "#     final_output['true_BGL_value'] = test_gl_value\n",
    "    final_output['predicted_BGL_value'] = scaled_prediction\n",
    "    \n",
    "    return (final_output, math.sqrt(mean_squared_error(scaled_prediction, y_test_data)), mean_absolute_error(scaled_prediction, y_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1103 samples\n",
      "Epoch 1/20\n",
      "1103/1103 [==============================] - 11s 10ms/sample - loss: 0.3987\n",
      "Epoch 2/20\n",
      "1103/1103 [==============================] - 8s 8ms/sample - loss: 0.0429\n",
      "Epoch 3/20\n",
      "1103/1103 [==============================] - 8s 8ms/sample - loss: 0.0283\n",
      "Epoch 4/20\n",
      "1103/1103 [==============================] - 9s 8ms/sample - loss: 0.0332\n",
      "Epoch 5/20\n",
      "1103/1103 [==============================] - 10s 9ms/sample - loss: 0.0299\n",
      "Epoch 6/20\n",
      "1103/1103 [==============================] - 10s 9ms/sample - loss: 0.0216\n",
      "Epoch 7/20\n",
      "1103/1103 [==============================] - 10s 9ms/sample - loss: 0.0173\n",
      "Epoch 8/20\n",
      "1103/1103 [==============================] - 9s 8ms/sample - loss: 0.0171\n",
      "Epoch 9/20\n",
      "1103/1103 [==============================] - 9s 8ms/sample - loss: 0.0166\n",
      "Epoch 10/20\n",
      "1103/1103 [==============================] - 9s 8ms/sample - loss: 0.0143\n",
      "Epoch 11/20\n",
      "1103/1103 [==============================] - 9s 8ms/sample - loss: 0.0156\n",
      "Epoch 12/20\n",
      "1103/1103 [==============================] - 10s 9ms/sample - loss: 0.0143\n",
      "Epoch 13/20\n",
      "1103/1103 [==============================] - 10s 9ms/sample - loss: 0.0135\n",
      "Epoch 14/20\n",
      "1103/1103 [==============================] - 11s 10ms/sample - loss: 0.0139\n",
      "Epoch 15/20\n",
      "1103/1103 [==============================] - 12s 11ms/sample - loss: 0.0129\n",
      "Epoch 16/20\n",
      "1103/1103 [==============================] - 13s 12ms/sample - loss: 0.0943\n",
      "Epoch 17/20\n",
      "1103/1103 [==============================] - 13s 12ms/sample - loss: 0.0134\n",
      "Epoch 18/20\n",
      "1103/1103 [==============================] - 12s 11ms/sample - loss: 0.0126\n",
      "Epoch 19/20\n",
      "1103/1103 [==============================] - 13s 12ms/sample - loss: 0.0123\n",
      "Epoch 20/20\n",
      "1103/1103 [==============================] - 13s 12ms/sample - loss: 0.0123\n",
      "584-ws-training.csv - 36.58627214060872\n",
      "584-ws-training.csv - 27.281584626498926\n",
      "Train on 1127 samples\n",
      "Epoch 1/20\n",
      "1127/1127 [==============================] - 19s 17ms/sample - loss: 0.4881\n",
      "Epoch 2/20\n",
      "1127/1127 [==============================] - 14s 13ms/sample - loss: 0.0761\n",
      "Epoch 3/20\n",
      "1127/1127 [==============================] - 12s 11ms/sample - loss: 0.0317\n",
      "Epoch 4/20\n",
      "1127/1127 [==============================] - 12s 11ms/sample - loss: 0.0254\n",
      "Epoch 5/20\n",
      "1127/1127 [==============================] - 12s 11ms/sample - loss: 0.0448\n",
      "Epoch 6/20\n",
      "1127/1127 [==============================] - 12s 10ms/sample - loss: 0.0149\n",
      "Epoch 7/20\n",
      "1127/1127 [==============================] - 11s 10ms/sample - loss: 0.0141\n",
      "Epoch 8/20\n",
      "1127/1127 [==============================] - 10s 9ms/sample - loss: 0.0137\n",
      "Epoch 9/20\n",
      "1127/1127 [==============================] - 10s 9ms/sample - loss: 0.0129\n",
      "Epoch 10/20\n",
      "1127/1127 [==============================] - 10s 9ms/sample - loss: 0.0137\n",
      "Epoch 11/20\n",
      "1127/1127 [==============================] - 10s 9ms/sample - loss: 0.0308\n",
      "Epoch 12/20\n",
      "1127/1127 [==============================] - 10s 8ms/sample - loss: 0.0114\n",
      "Epoch 13/20\n",
      "1127/1127 [==============================] - 9s 8ms/sample - loss: 0.0112\n",
      "Epoch 14/20\n",
      "1127/1127 [==============================] - 9s 8ms/sample - loss: 0.0108\n",
      "Epoch 15/20\n",
      "1127/1127 [==============================] - 9s 8ms/sample - loss: 0.0110\n",
      "Epoch 16/20\n",
      "1127/1127 [==============================] - 8s 7ms/sample - loss: 0.1010\n",
      "Epoch 17/20\n",
      "1127/1127 [==============================] - 8s 7ms/sample - loss: 0.0105\n",
      "Epoch 18/20\n",
      "1127/1127 [==============================] - 8s 7ms/sample - loss: 0.0101\n",
      "Epoch 19/20\n",
      "1127/1127 [==============================] - 8s 7ms/sample - loss: 0.0104\n",
      "Epoch 20/20\n",
      "1127/1127 [==============================] - 8s 7ms/sample - loss: 0.0104\n",
      "567-ws-training.csv - 36.342665258311776\n",
      "567-ws-training.csv - 25.704366561534126\n",
      "Train on 1135 samples\n",
      "Epoch 1/20\n",
      "1135/1135 [==============================] - 11s 10ms/sample - loss: 0.7991\n",
      "Epoch 2/20\n",
      "1135/1135 [==============================] - 8s 7ms/sample - loss: 0.0572\n",
      "Epoch 3/20\n",
      "1135/1135 [==============================] - 8s 7ms/sample - loss: 0.0574\n",
      "Epoch 4/20\n",
      "1135/1135 [==============================] - 8s 7ms/sample - loss: 0.0391\n",
      "Epoch 5/20\n",
      "1135/1135 [==============================] - 8s 7ms/sample - loss: 0.0275\n",
      "Epoch 6/20\n",
      "1135/1135 [==============================] - 8s 7ms/sample - loss: 0.0284\n",
      "Epoch 7/20\n",
      "1135/1135 [==============================] - 8s 7ms/sample - loss: 0.0231\n",
      "Epoch 8/20\n",
      "1135/1135 [==============================] - 8s 7ms/sample - loss: 0.0155\n",
      "Epoch 9/20\n",
      "1135/1135 [==============================] - 8s 7ms/sample - loss: 0.0131\n",
      "Epoch 10/20\n",
      "1135/1135 [==============================] - 8s 7ms/sample - loss: 0.0147\n",
      "Epoch 11/20\n",
      "1135/1135 [==============================] - 8s 7ms/sample - loss: 0.0190\n",
      "Epoch 12/20\n",
      "1135/1135 [==============================] - 8s 7ms/sample - loss: 0.0123\n",
      "Epoch 13/20\n",
      "1135/1135 [==============================] - 8s 7ms/sample - loss: 0.0126\n",
      "Epoch 14/20\n",
      "1135/1135 [==============================] - 8s 7ms/sample - loss: 0.0107\n",
      "Epoch 15/20\n",
      "1135/1135 [==============================] - 8s 7ms/sample - loss: 0.0110\n",
      "Epoch 16/20\n",
      "1135/1135 [==============================] - 8s 7ms/sample - loss: 0.0109\n",
      "Epoch 17/20\n",
      "1135/1135 [==============================] - 8s 7ms/sample - loss: 0.0107\n",
      "Epoch 18/20\n",
      "1135/1135 [==============================] - 8s 7ms/sample - loss: 0.0103\n",
      "Epoch 19/20\n",
      "1135/1135 [==============================] - 8s 7ms/sample - loss: 0.0108\n",
      "Epoch 20/20\n",
      "1135/1135 [==============================] - 8s 7ms/sample - loss: 0.0106\n",
      "596-ws-training.csv - 27.949341801716947\n",
      "596-ws-training.csv - 21.195401124500087\n",
      "Train on 924 samples\n",
      "Epoch 1/20\n",
      "924/924 [==============================] - 9s 10ms/sample - loss: 0.4375\n",
      "Epoch 2/20\n",
      "924/924 [==============================] - 6s 7ms/sample - loss: 0.0635\n",
      "Epoch 3/20\n",
      "924/924 [==============================] - 6s 7ms/sample - loss: 0.0299\n",
      "Epoch 4/20\n",
      "924/924 [==============================] - 7s 7ms/sample - loss: 0.0315\n",
      "Epoch 5/20\n",
      "924/924 [==============================] - 6s 7ms/sample - loss: 0.0248\n",
      "Epoch 6/20\n",
      "924/924 [==============================] - 7s 7ms/sample - loss: 0.0195\n",
      "Epoch 7/20\n",
      "924/924 [==============================] - 7s 7ms/sample - loss: 0.0226\n",
      "Epoch 8/20\n",
      "924/924 [==============================] - 6s 7ms/sample - loss: 0.0174\n",
      "Epoch 9/20\n",
      "924/924 [==============================] - 6s 7ms/sample - loss: 0.0158\n",
      "Epoch 10/20\n",
      "924/924 [==============================] - 6s 7ms/sample - loss: 0.0153\n",
      "Epoch 11/20\n",
      "924/924 [==============================] - 6s 7ms/sample - loss: 0.0160\n",
      "Epoch 12/20\n",
      "924/924 [==============================] - 6s 7ms/sample - loss: 0.0166\n",
      "Epoch 13/20\n",
      "924/924 [==============================] - 6s 7ms/sample - loss: 0.0140\n",
      "Epoch 14/20\n",
      "924/924 [==============================] - 6s 7ms/sample - loss: 0.0136\n",
      "Epoch 15/20\n",
      "924/924 [==============================] - 5s 6ms/sample - loss: 0.0138\n",
      "Epoch 16/20\n",
      "924/924 [==============================] - 5s 6ms/sample - loss: 0.0136\n",
      "Epoch 17/20\n",
      "924/924 [==============================] - 6s 6ms/sample - loss: 0.0134\n",
      "Epoch 18/20\n",
      "924/924 [==============================] - 5s 6ms/sample - loss: 0.0127\n",
      "Epoch 19/20\n",
      "924/924 [==============================] - 5s 6ms/sample - loss: 0.0127\n",
      "Epoch 20/20\n",
      "924/924 [==============================] - 5s 6ms/sample - loss: 0.0126\n",
      "552-ws-training.csv - 27.050176368016707\n",
      "552-ws-training.csv - 19.91595172236501\n",
      "Train on 1055 samples\n",
      "Epoch 1/20\n",
      "1055/1055 [==============================] - 9s 8ms/sample - loss: 0.4594\n",
      "Epoch 2/20\n",
      "1055/1055 [==============================] - 6s 6ms/sample - loss: 0.0337\n",
      "Epoch 3/20\n",
      "1055/1055 [==============================] - 6s 6ms/sample - loss: 0.0233\n",
      "Epoch 4/20\n",
      "1055/1055 [==============================] - 6s 6ms/sample - loss: 0.0481\n",
      "Epoch 5/20\n",
      "1055/1055 [==============================] - 6s 6ms/sample - loss: 0.0354\n",
      "Epoch 6/20\n",
      "1055/1055 [==============================] - 6s 6ms/sample - loss: 0.0129\n",
      "Epoch 7/20\n",
      "1055/1055 [==============================] - 6s 6ms/sample - loss: 0.0123\n",
      "Epoch 8/20\n",
      "1055/1055 [==============================] - 6s 6ms/sample - loss: 0.0112\n",
      "Epoch 9/20\n",
      "1055/1055 [==============================] - 6s 6ms/sample - loss: 0.0114\n",
      "Epoch 10/20\n",
      "1055/1055 [==============================] - 6s 6ms/sample - loss: 0.0115\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1055/1055 [==============================] - 6s 6ms/sample - loss: 0.0106\n",
      "Epoch 12/20\n",
      "1055/1055 [==============================] - 6s 6ms/sample - loss: 0.0091\n",
      "Epoch 13/20\n",
      "1055/1055 [==============================] - 6s 6ms/sample - loss: 0.0098\n",
      "Epoch 14/20\n",
      "1055/1055 [==============================] - 6s 6ms/sample - loss: 0.0094\n",
      "Epoch 15/20\n",
      "1055/1055 [==============================] - 6s 6ms/sample - loss: 0.0091\n",
      "Epoch 16/20\n",
      "1055/1055 [==============================] - 6s 6ms/sample - loss: 0.0093\n",
      "Epoch 17/20\n",
      "1055/1055 [==============================] - 6s 6ms/sample - loss: 0.0089\n",
      "Epoch 18/20\n",
      "1055/1055 [==============================] - 6s 6ms/sample - loss: 0.0087\n",
      "Epoch 19/20\n",
      "1055/1055 [==============================] - 6s 6ms/sample - loss: 0.0296\n",
      "Epoch 20/20\n",
      "1055/1055 [==============================] - 6s 6ms/sample - loss: 0.0094\n",
      "544-ws-training.csv - 118.34016668697706\n",
      "544-ws-training.csv - 28.73334791625707\n",
      "Train on 1092 samples\n",
      "Epoch 1/20\n",
      "1092/1092 [==============================] - 9s 8ms/sample - loss: 0.8648\n",
      "Epoch 2/20\n",
      "1092/1092 [==============================] - 6s 6ms/sample - loss: 0.0776\n",
      "Epoch 3/20\n",
      "1092/1092 [==============================] - 6s 6ms/sample - loss: 0.0467\n",
      "Epoch 4/20\n",
      "1092/1092 [==============================] - 6s 6ms/sample - loss: 0.0418\n",
      "Epoch 5/20\n",
      "1092/1092 [==============================] - 7s 6ms/sample - loss: 0.0278\n",
      "Epoch 6/20\n",
      "1092/1092 [==============================] - 6s 6ms/sample - loss: 0.0255\n",
      "Epoch 7/20\n",
      "1092/1092 [==============================] - 6s 6ms/sample - loss: 0.0304\n",
      "Epoch 8/20\n",
      "1092/1092 [==============================] - 6s 6ms/sample - loss: 0.0206\n",
      "Epoch 9/20\n",
      "1092/1092 [==============================] - 6s 6ms/sample - loss: 0.0188\n",
      "Epoch 10/20\n",
      "1092/1092 [==============================] - 6s 6ms/sample - loss: 0.0169\n",
      "Epoch 11/20\n",
      "1092/1092 [==============================] - 6s 6ms/sample - loss: 0.0170\n",
      "Epoch 12/20\n",
      "1092/1092 [==============================] - 6s 6ms/sample - loss: 0.0159\n",
      "Epoch 13/20\n",
      "1092/1092 [==============================] - 7s 6ms/sample - loss: 0.0156\n",
      "Epoch 14/20\n",
      "1092/1092 [==============================] - 6s 6ms/sample - loss: 0.0149\n",
      "Epoch 15/20\n",
      "1092/1092 [==============================] - 6s 6ms/sample - loss: 0.0140\n",
      "Epoch 16/20\n",
      "1092/1092 [==============================] - 6s 6ms/sample - loss: 0.0150\n",
      "Epoch 17/20\n",
      "1092/1092 [==============================] - 6s 6ms/sample - loss: 0.0139\n",
      "Epoch 18/20\n",
      "1092/1092 [==============================] - 6s 6ms/sample - loss: 0.0141\n",
      "Epoch 19/20\n",
      "1092/1092 [==============================] - 6s 6ms/sample - loss: 0.0309\n",
      "Epoch 20/20\n",
      "1092/1092 [==============================] - 7s 6ms/sample - loss: 0.0133\n",
      "540-ws-training.csv - 38.65145942671502\n",
      "540-ws-training.csv - 30.241952693360574\n",
      "time: 16min 16s\n"
     ]
    }
   ],
   "source": [
    "test_data_list = ['540-ws-training.csv', '544-ws-training.csv', '552-ws-training.csv', '567-ws-training.csv', '584-ws-training.csv', '596-ws-training.csv']\n",
    "\n",
    "rmse_list = {}\n",
    "mae_list = {}\n",
    "for file in os.listdir('../data/derived/60_min_complete_dataset/'):\n",
    "    if file in test_data_list:\n",
    "        train_data = pd.read_csv('../data/derived/60_min_complete_dataset/'+file)\n",
    "        test_data = pd.read_csv('../data/derived_test/60_min_complete_dataset/'+file[0:7]+'testing.csv')\n",
    "        final_output, rmse_error, mae_error = model(test_data, train_data)\n",
    "        rmse_list[file] = rmse_error\n",
    "        mae_list[file] = mae_error\n",
    "        print ('{} - {}'.format(file, rmse_error))\n",
    "        print ('{} - {}'.format(file, mae_error))\n",
    "        final_output.to_csv('../data/output/tcn/'+file[0:7]+'result_60min.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'584-ws-training.csv': 36.58627214060872,\n",
       " '567-ws-training.csv': 36.342665258311776,\n",
       " '596-ws-training.csv': 27.949341801716947,\n",
       " '552-ws-training.csv': 27.050176368016707,\n",
       " '544-ws-training.csv': 118.34016668697706,\n",
       " '540-ws-training.csv': 38.65145942671502}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.13 ms\n"
     ]
    }
   ],
   "source": [
    "rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'584-ws-training.csv': 27.281584626498926,\n",
       " '567-ws-training.csv': 25.704366561534126,\n",
       " '596-ws-training.csv': 21.195401124500087,\n",
       " '552-ws-training.csv': 19.91595172236501,\n",
       " '544-ws-training.csv': 28.73334791625707,\n",
       " '540-ws-training.csv': 30.241952693360574}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.46 ms\n"
     ]
    }
   ],
   "source": [
    "mae_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean - RMSE : 47.48668028039104\n",
      "Standard Deviation - RMSE : 31.991259011690556\n",
      "Mean - MAE : 25.512100774085965\n",
      "Standard Deviation - MAE : 3.7830047942518896\n",
      "time: 5.78 ms\n"
     ]
    }
   ],
   "source": [
    "from statistics import pstdev, mean\n",
    "\n",
    "rmse_values = rmse_list.values()\n",
    "mae_values = mae_list.values()\n",
    "\n",
    "print ('Mean - RMSE : {}'.format(mean(rmse_values)))\n",
    "print ('Standard Deviation - RMSE : {}'.format(pstdev(rmse_values)))\n",
    "\n",
    "print ('Mean - MAE : {}'.format(mean(mae_values)))\n",
    "print ('Standard Deviation - MAE : {}'.format(pstdev(mae_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
